{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Module 9 part of Tensorflow Lite"
      ],
      "metadata": {
        "id": "dXJN01zcm2_5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5kCQaPIumu4r"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/DataTalksClub/machine-learning-zoomcamp/releases/download/chapter7-model/xception_v4_large_08_0.894.h5 -O clothing-model.h5"
      ],
      "metadata": {
        "id": "eUtHUMSvn24f"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('clothing-model.h5')"
      ],
      "metadata": {
        "id": "eZ9NHBgNn_P9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download the picture\n",
        "!wget http://bit.ly/mlbookcamp-pants -O pants.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWO_ajcDoRUN",
        "outputId": "a290e28f-71c3-4c76-c234-f2d342e530b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-27 07:15:16--  http://bit.ly/mlbookcamp-pants\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.11|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/alexeygrigorev/clothing-dataset-small/master/test/pants/4aabd82c-82e1-4181-a84d-d0c6e550d26d.jpg [following]\n",
            "--2023-11-27 07:15:16--  https://raw.githubusercontent.com/alexeygrigorev/clothing-dataset-small/master/test/pants/4aabd82c-82e1-4181-a84d-d0c6e550d26d.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23048 (23K) [image/jpeg]\n",
            "Saving to: ‘pants.jpg’\n",
            "\n",
            "pants.jpg           100%[===================>]  22.51K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-11-27 07:15:16 (15.8 MB/s) - ‘pants.jpg’ saved [23048/23048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "XVS28s5Eod4I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = load_img('pants.jpg', target_size=(299,299))"
      ],
      "metadata": {
        "id": "chmlwqQdoknv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(img)\n",
        "X = np.array([X])\n",
        "\n",
        "X = preprocess_input(X)"
      ],
      "metadata": {
        "id": "78uZ-DQfpEUc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqm5GZn7pNoW",
        "outputId": "3f6d61b6-5cb0-4607-f588-8f7b59267db5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    'dress',\n",
        "    'hat',\n",
        "    'longsleeve',\n",
        "    'outwear',\n",
        "    'pants',\n",
        "    'shirt',\n",
        "    'shoes',\n",
        "    'shorts',\n",
        "    'skirt',\n",
        "    't-shirt'\n",
        "]\n",
        "\n",
        "dict(zip(classes, preds[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHRtCeUsp2Rv",
        "outputId": "aefbf8ac-c05f-400c-8926-33d8a554beba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dress': -1.8798649,\n",
              " 'hat': -4.7563114,\n",
              " 'longsleeve': -2.359532,\n",
              " 'outwear': -1.0892639,\n",
              " 'pants': 9.903785,\n",
              " 'shirt': -2.8261807,\n",
              " 'shoes': -3.648312,\n",
              " 'shorts': 3.2411556,\n",
              " 'skirt': -2.612096,\n",
              " 't-shirt': -4.8520355}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert keras to TF-Lite"
      ],
      "metadata": {
        "id": "tNvjnEolp-Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('clothing-model.tflite', 'wb') as f_out:\n",
        "  f_out.write(tflite_model)"
      ],
      "metadata": {
        "id": "Ox0PP2n9qCX0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.lite as tflite"
      ],
      "metadata": {
        "id": "5IihlZksqxZV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tflite.Interpreter(model_path='clothing-model.tflite')\n",
        "interpreter.allocate_tensors()"
      ],
      "metadata": {
        "id": "TbJqyf7Nrfp0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.get_input_details()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbpjFvG4rzcx",
        "outputId": "ec372cf7-c236-4aeb-bba0-628c2a69fd93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'serving_default_input_8:0',\n",
              "  'index': 0,\n",
              "  'shape': array([  1, 299, 299,   3], dtype=int32),\n",
              "  'shape_signature': array([ -1, 299, 299,   3], dtype=int32),\n",
              "  'dtype': numpy.float32,\n",
              "  'quantization': (0.0, 0),\n",
              "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
              "   'zero_points': array([], dtype=int32),\n",
              "   'quantized_dimension': 0},\n",
              "  'sparsity_parameters': {}}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_index = interpreter.get_input_details()[0]['index']"
      ],
      "metadata": {
        "id": "y_Z2iP_YuNZS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#need to see the output too\n",
        "interpreter.get_output_details()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xTQHfmsuWyw",
        "outputId": "d9f94dc6-4882-4d45-9381-1829c6a491ad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'StatefulPartitionedCall:0',\n",
              "  'index': 229,\n",
              "  'shape': array([ 1, 10], dtype=int32),\n",
              "  'shape_signature': array([-1, 10], dtype=int32),\n",
              "  'dtype': numpy.float32,\n",
              "  'quantization': (0.0, 0),\n",
              "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
              "   'zero_points': array([], dtype=int32),\n",
              "   'quantized_dimension': 0},\n",
              "  'sparsity_parameters': {}}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_index = interpreter.get_output_details()[0]['index']"
      ],
      "metadata": {
        "id": "62g_9Tx8uqZl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.set_tensor(input_index, X)\n",
        "interpreter.invoke()\n",
        "preds = interpreter.get_tensor(output_index)"
      ],
      "metadata": {
        "id": "Hpc56qg5u1uj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now try to predict\n",
        "classes = [\n",
        "    'dress',\n",
        "    'hat',\n",
        "    'longsleeve',\n",
        "    'outwear',\n",
        "    'pants',\n",
        "    'shirt',\n",
        "    'shoes',\n",
        "    'shorts',\n",
        "    'skirt',\n",
        "    't-shirt'\n",
        "]\n",
        "\n",
        "dict(zip(classes, preds[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m33Y6udLvV8j",
        "outputId": "1fd34213-8945-4e38-ece1-a807706d8dab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dress': -1.8798652,\n",
              " 'hat': -4.7563086,\n",
              " 'longsleeve': -2.3595319,\n",
              " 'outwear': -1.0892631,\n",
              " 'pants': 9.903782,\n",
              " 'shirt': -2.8261807,\n",
              " 'shoes': -3.648309,\n",
              " 'shorts': 3.2411587,\n",
              " 'skirt': -2.6120942,\n",
              " 't-shirt': -4.8520336}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing TF Dependency"
      ],
      "metadata": {
        "id": "DJKZz_2WwM1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to change the load_img (aka write from scratch)\n",
        "#before: img = load_img('pants.jpg', target_size=(299,299))\n",
        "#after:\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "with Image.open('pants.jpg') as img:\n",
        "  img = img.resize((299, 299), Image.NEAREST)"
      ],
      "metadata": {
        "id": "ykmIAcdKwmVh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now write from scratch for preprocess_input()\n",
        "\n",
        "def preprocess_input(x):\n",
        "  x /= 127.5\n",
        "  x -= 1.\n",
        "  return x"
      ],
      "metadata": {
        "id": "K3TbL9WLxrSs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(img, dtype = 'float32')\n",
        "X = np.array([X])\n",
        "\n",
        "X = preprocess_input(X)"
      ],
      "metadata": {
        "id": "5lDssQZ5vsaO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now try to predict\n",
        "classes = [\n",
        "    'dress',\n",
        "    'hat',\n",
        "    'longsleeve',\n",
        "    'outwear',\n",
        "    'pants',\n",
        "    'shirt',\n",
        "    'shoes',\n",
        "    'shorts',\n",
        "    'skirt',\n",
        "    't-shirt'\n",
        "]\n",
        "\n",
        "dict(zip(classes, preds[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igbfAgrgyWBx",
        "outputId": "64727b30-2336-4a6b-f1ac-54fa3df9344a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dress': -1.8798652,\n",
              " 'hat': -4.7563086,\n",
              " 'longsleeve': -2.3595319,\n",
              " 'outwear': -1.0892631,\n",
              " 'pants': 9.903782,\n",
              " 'shirt': -2.8261807,\n",
              " 'shoes': -3.648309,\n",
              " 'shorts': 3.2411587,\n",
              " 'skirt': -2.6120942,\n",
              " 't-shirt': -4.8520336}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simpler doing of removing tf depedency"
      ],
      "metadata": {
        "id": "TKpJXl5Eyglj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-image-helper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ8wTE6eylrT",
        "outputId": "fa728bfa-603f-4f6c-9a86-bd442a7b92a1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-image-helper\n",
            "  Downloading keras_image_helper-0.0.1-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-image-helper) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras-image-helper) (9.4.0)\n",
            "Installing collected packages: keras-image-helper\n",
            "Successfully installed keras-image-helper-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --extra-index-url https://google-coral.github.io/py-repo/ tflite_runtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNV6rQOm7fST",
        "outputId": "08139515-3d55-4bb8-ce49-c97f8f8f6582"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://google-coral.github.io/py-repo/\n",
            "Collecting tflite_runtime\n",
            "  Downloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.10/dist-packages (from tflite_runtime) (1.23.5)\n",
            "Installing collected packages: tflite_runtime\n",
            "Successfully installed tflite_runtime-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#import tensorflow.lite as tflite\n",
        "import tflite_runtime.interpreter as tflite\n",
        "from keras_image_helper import create_preprocessor"
      ],
      "metadata": {
        "id": "Us2fJPQFzff1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tflite.Interpreter(model_path='clothing-model.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0]['index']\n",
        "output_index = interpreter.get_output_details()[0]['index']"
      ],
      "metadata": {
        "id": "-s1fntuH8DJr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = create_preprocessor('xception', target_size=(299, 299))"
      ],
      "metadata": {
        "id": "2r8YNmUh8GMR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://bit.ly/mlbookcamp-pants'\n",
        "X = preprocessor.from_url(url)"
      ],
      "metadata": {
        "id": "JncVQ5V58Ikp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.set_tensor(input_index, X)\n",
        "interpreter.invoke()\n",
        "preds = interpreter.get_tensor(output_index)"
      ],
      "metadata": {
        "id": "UYI5LxFy8LAJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    'dress',\n",
        "    'hat',\n",
        "    'longsleeve',\n",
        "    'outwear',\n",
        "    'pants',\n",
        "    'shirt',\n",
        "    'shoes',\n",
        "    'shorts',\n",
        "    'skirt',\n",
        "    't-shirt'\n",
        "]\n",
        "\n",
        "dict(zip(classes, preds[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XdUi9Eg8NRJ",
        "outputId": "1cb4a048-641f-44aa-c5b7-4918a08cc69d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dress': -1.8798652,\n",
              " 'hat': -4.7563086,\n",
              " 'longsleeve': -2.3595319,\n",
              " 'outwear': -1.0892631,\n",
              " 'pants': 9.903782,\n",
              " 'shirt': -2.8261807,\n",
              " 'shoes': -3.648309,\n",
              " 'shorts': 3.2411587,\n",
              " 'skirt': -2.6120942,\n",
              " 't-shirt': -4.8520336}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}